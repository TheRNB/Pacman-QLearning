{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent and Environment\n",
    "We should first come up with action way to represent states and actions in the game. Each action can be simply mapped to moving either four directions. We also represent the current state of the agent represent the immediate cells around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state space and the action space\n",
    "state_space = 3**8 # The number of possible states, each cell being Wall, Empty, or Dot, Agent\n",
    "action_space = 4 # The number of possible actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-table\n",
    "Now we initialize the Q table being state_space * action_space which initially is filled with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize the Q-table with zeros\n",
    "Q = np.zeros((state_space, action_space))\n",
    "\n",
    "def encode(state, isShortened=False):\n",
    "    result = 0\n",
    "    # if the input matrix is the whole playable area\n",
    "    if isShortened == False:\n",
    "        for row in range(len(state)):\n",
    "            for column in range(len(state[row])):\n",
    "                if state[row][column] == 'A':\n",
    "                    temp = [state[row-1][i] for i in range(column-1, column+2)]\n",
    "                    temp.append(state[row][column-1])\n",
    "                    temp.append(state[row][column+1])\n",
    "                    temp += [state[row+1][i] for i in range(column-1, column+2)]\n",
    "                    #print(temp)\n",
    "                    for cell in temp:\n",
    "                        result *= 3\n",
    "                        if (cell == 'W'):\n",
    "                            result += 0\n",
    "                        elif (cell == 'D'):\n",
    "                            result += 1\n",
    "                        elif (cell == 'E'):\n",
    "                            result += 2\n",
    "    else:\n",
    "        for row in range(len(state)):\n",
    "            for column in range(len(state[row])):\n",
    "                if row == 1 and column == 1:\n",
    "                    continue\n",
    "                result *= 3\n",
    "                if (state[row][column] == 'W'):\n",
    "                    result += 0\n",
    "                elif (state[row][column] == 'D'):\n",
    "                    result += 1\n",
    "                elif (state[row][column] == 'E'):\n",
    "                    result += 2\n",
    "    return result\n",
    "\n",
    "def decode(encoding):\n",
    "    state = [['A' for _ in range(3)]for _ in range(3)]\n",
    "    for row in range(2, -1, -1):\n",
    "        for column in range(2, -1, -1):\n",
    "            if(row == 1 and column == 1):\n",
    "                continue\n",
    "\n",
    "            remainder = encoding % 3\n",
    "            encoding = encoding // 3\n",
    "            if remainder == 0:\n",
    "                state[row][column] = 'W'\n",
    "            elif remainder == 1:\n",
    "                state[row][column] = 'D'\n",
    "            elif remainder == 2:\n",
    "                state[row][column] = 'E'\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Now before training the mode we should define our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate, the discount factor, and the maximum number of episodes\n",
    "learning_rate = 0.2 # How much to update the Q-value (Alpha)\n",
    "discount_factor = 0.9 # How much to discount the future reward (Gamma)\n",
    "max_episodes = 1000 # How many episodes to train the agent\n",
    "max_iteration = 1000 # How many iterations to go each episode\n",
    "epsilon = 0.1 # How much to explore randomly\n",
    "# REMEBER TO MAKE EPSILON MOVE GRADUALLY ACCORDING TO max_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_possible_reward(state, action):\n",
    "    \"\"\"\n",
    "    gets a state and a planned action and \n",
    "    calculates the possible reward for that action\n",
    "\n",
    "    Args:\n",
    "        state (int_encoding): and encoding of the current state of the agent\n",
    "        action (int): a string showing what the next action of agent is going to be\n",
    "\n",
    "    Returns:\n",
    "        int: the possible reward to get\n",
    "    \"\"\"\n",
    "    # Initial reward\n",
    "    reward = 0\n",
    "    # Get the destination cell of next action\n",
    "    temp = decode(state)\n",
    "    if action == 'up':\n",
    "        temp = temp[0][1]\n",
    "    elif action == 'down':\n",
    "        temp = temp[2][1]\n",
    "    elif action == 'right':\n",
    "        temp = temp[1][2]\n",
    "    elif action == 'left':\n",
    "        temp = temp[1][0]\n",
    "    \n",
    "    # Calculate the reward. NOTE: cell cannot be WALL.\n",
    "    if temp == 'D':\n",
    "        reward += 10\n",
    "    elif temp == 'E':\n",
    "        reward -= 2\n",
    "\n",
    "    return reward\n",
    "\n",
    "def move_next_state(environment, action):\n",
    "    \"\"\"\n",
    "    gets an environment and proceeds to run the action on the environment\n",
    "\n",
    "    Args:\n",
    "        environment (list(string) ** 2): a list of lists of characters showing the current environment\n",
    "        action (string): a string showin the next action to take\n",
    "\n",
    "    Returns:\n",
    "        list(string) ** 2: the new environment after taking the action\n",
    "    \"\"\"\n",
    "    for row in range(1, len(environment)):\n",
    "        for column in range(1, len(environment[row])):\n",
    "            if environment[row][column] == 'A':\n",
    "                #print (row, column)\n",
    "                # Clear the previous cell of agent\n",
    "                environment[row][column] = 'E'\n",
    "                # Move the agent to the next position\n",
    "                if action == 'up':\n",
    "                    environment[row-1][column] = 'A'\n",
    "                elif action == 'down':\n",
    "                    environment[row+1][column] = 'A'\n",
    "                elif action == 'right':\n",
    "                    environment[row][column+1] = 'A'\n",
    "                elif action == 'left':\n",
    "                    environment[row][column-1] = 'A'\n",
    "                    \n",
    "                #print(*environment, sep='\\n')\n",
    "                #print(\"in move_next_state, action=\", action)\n",
    "                #print(\"\\n\\n\\n\")\n",
    "                \n",
    "                return environment\n",
    "\n",
    "def get_next_action(state):\n",
    "    \"\"\"\n",
    "    gets the environment and current state, based on the epsilon value either selects a random action\n",
    "    or uses the Q table to look for the most profitable action to take\n",
    "\n",
    "    Args:\n",
    "        environment (list(string)**2): the environment of the game\n",
    "        state (int_encoding): the encoding of the current state of the agent\n",
    "\n",
    "    Returns:\n",
    "        string: (random/best) action to take in the current state\n",
    "    \"\"\"\n",
    "    temp = decode(state)\n",
    "    explore = random.random()\n",
    "    # RANDOM ACTION\n",
    "   #print(\"in get next action\", temp)\n",
    "    if explore > epsilon:\n",
    "    #if True:\n",
    "        range = 0\n",
    "        if temp[0][1] != 'W':\n",
    "            #print(\"empty up\")\n",
    "            range += 1\n",
    "        if temp[1][0] != 'W':\n",
    "            #print(\"empty left\")\n",
    "            range += 1\n",
    "        if temp[1][2] != 'W':\n",
    "            #print(\"empty right\")\n",
    "            range += 1\n",
    "        if temp[2][1] != 'W':\n",
    "            #print(\"empty down\")\n",
    "            range += 1\n",
    "        #print(\"in get next action, range=\", range)  \n",
    "        move = random.randint(0, (range-1))\n",
    "        \n",
    "        iterator = 0\n",
    "        #print(\"in get next action, move=\", move)\n",
    "        if temp[0][1] != 'W':\n",
    "            #print(\"in if1, iterator = \", iterator)\n",
    "            if move == iterator:\n",
    "                #print(\"range is\", range, \"move is\", move, \"took up\")\n",
    "                return 'up'\n",
    "            iterator += 1\n",
    "        if temp[1][2] != 'W':\n",
    "            #print(\"in if2, iterator = \", iterator)\n",
    "            if move == iterator:\n",
    "                #print(\"range is\", range, \"move is\", move, \"took right\")\n",
    "                return 'right'\n",
    "            iterator += 1\n",
    "        if temp[2][1] != 'W':\n",
    "            #print(\"in if3, iterator = \", iterator)\n",
    "            if move == iterator:\n",
    "                #print(\"range is\", range, \"move is\", move, \"took down\")\n",
    "                return 'down'\n",
    "            iterator += 1\n",
    "        \n",
    "        #print(\"DEBUG: TOOK LEFT AS THE ONLY OPTION\", iterator, range, temp)   \n",
    "        #print(\"range is\", range, \"move is\", move, \"took left\")                         # DEBUG\n",
    "        return 'left'\n",
    "    # BEST ACTION\n",
    "    else:\n",
    "        # Next action first assumed to be unknown\n",
    "        best_move = 'NULL'\n",
    "        best_move_score = -1e9\n",
    "        temp2 = Q[state][0]#up\n",
    "        if (temp[0][1] != 'W' and temp2 > best_move_score):\n",
    "            best_move_score = temp2\n",
    "            best_move = 'up'\n",
    "        temp2 = Q[state][1]#down\n",
    "        if (temp[2][1] != 'W' and temp2 > best_move_score):\n",
    "            best_move_score = temp2\n",
    "            best_move = 'down'\n",
    "        temp2 = Q[state][2]#left\n",
    "        if (temp[1][0] != 'W' and temp2 > best_move_score):\n",
    "            best_move_score = temp2\n",
    "            best_move = 'left'\n",
    "        temp2 = Q[state][3]#right\n",
    "        if (temp[1][2] != 'W' and temp2 > best_move_score):\n",
    "            best_move_score = temp2\n",
    "            best_move = 'right'\n",
    "\n",
    "        if best_move == 'NULL':\n",
    "            raise Exception(\"THE AGENT HAS GOTTEN STUCK BETWEEN 4 WALLS\", temp)                     # DEBUG\n",
    "\n",
    "        return best_move\n",
    "    \n",
    "def update_Q(prev_state, prev_action, reward, new_state):\n",
    "    \"\"\"\n",
    "    Updating the Q values after taking an action\n",
    "\n",
    "    Args:\n",
    "        prev_state (int_encoding): an encoding of the previous state agent was in\n",
    "        prev_action (string): a string showin the previous action agent has taken\n",
    "        reward (int): an integer showing the immediate reward gathered by taking the previous action\n",
    "        newState (int_encoding): an encoding of the current state agent is in\n",
    "    \"\"\"\n",
    "    if prev_action == 'up':\n",
    "        prev_action = 0\n",
    "    elif prev_action == 'down':\n",
    "        prev_action = 1\n",
    "    elif prev_action == 'left':\n",
    "        prev_action = 2\n",
    "    elif prev_action == 'right':\n",
    "        prev_action = 3\n",
    "\n",
    "    max_Q = Q[new_state][3]\n",
    "    for i in range(3):\n",
    "        max_Q = max(Q[new_state][i], max_Q)\n",
    "    Q[prev_state][prev_action] = (((1-learning_rate) * Q[prev_state][prev_action]) + \n",
    "                                (learning_rate * (reward + (discount_factor * max_Q))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from pygame.locals import *\n",
    "def test_game(environment):\n",
    "    pygame.init()\n",
    "    # Set up the display\n",
    "    cell_size = 100  # Size of each cell in pixels\n",
    "    map_width = 11  # mber of cells in the horizontal direction\n",
    "    map_height = 9 # Number of cells in the vertical direction\n",
    "    screen_width = cell_size * map_width\n",
    "    screen_height = cell_size * map_height\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "    pygame.display.set_caption(\"Pacman\")\n",
    "    # Define colors\n",
    "    font = pygame.font.Font(None, 24)\n",
    "    WHITE = (255, 255, 255)\n",
    "    BLACK = (0, 0, 0)\n",
    "    BLUE = (0, 0, 255)\n",
    "    GREEN = (0, 255, 0)\n",
    "    environment = [['W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'],\n",
    "               ['W', 'A', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'W', 'W', 'D', 'W', 'W', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'D', 'D', 'D', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'D', 'D', 'W', 'E', 'W', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'W', 'E', 'W', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'D', 'W', 'D', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W']]\n",
    "    global epsilon\n",
    "    epsilon = 0.1\n",
    "    dot_count = 0\n",
    "    for list in environment:\n",
    "        dot_count += list.count('D')\n",
    "    while (dot_count > 0):\n",
    "        dot_count = 0\n",
    "        for list in environment:\n",
    "            dot_count += list.count('D')\n",
    "        #print(dot_count, epsilon)\n",
    "        epsilon = 1.1\n",
    "\n",
    "        current_state = encode(environment)\n",
    "        # Choose action\n",
    "        action = get_next_action(current_state)\n",
    "        # Get Reward\n",
    "        reward = get_possible_reward(current_state, action)\n",
    "        # Update Environment\n",
    "        environment = move_next_state(environment, action)\n",
    "        # Update Q\n",
    "        update_Q(current_state, action, reward, encode(environment))\n",
    "\n",
    "\n",
    "        screen.fill(BLACK)\n",
    "        # Render the map\n",
    "        running = True\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "        if not running:\n",
    "            break\n",
    "        for x in range(map_height):\n",
    "            for y in range(map_width):\n",
    "                cell_color = WHITE\n",
    "                if environment[x][y] == 'W':\n",
    "                    cell_color = BLACK\n",
    "                if environment[x][y] == 'D':\n",
    "                    cell_color = BLUE\n",
    "                if environment[x][y] == 'A':\n",
    "                    cell_color = GREEN\n",
    "                rectangle = pygame.Rect(y * cell_size, x * cell_size, cell_size, cell_size)\n",
    "                    #cell_color = GREEN\n",
    "                pygame.draw.rect(screen, cell_color, rectangle)\n",
    "                \n",
    "                \n",
    "        score_text = font.render(f\"Current Move Score: {reward}\", True, WHITE)\n",
    "        screen.blit(score_text, (10, 10))\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "        pygame.time.delay(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(max_episodes):\n",
    "    environment = [['W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'],\n",
    "               ['W', 'A', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'W', 'W', 'D', 'W', 'W', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'D', 'D', 'D', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'D', 'D', 'W', 'E', 'W', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'W', 'E', 'W', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'W', 'D', 'D', 'W', 'D', 'D', 'W', 'D', 'W'],\n",
    "               ['W', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'W'],\n",
    "               ['W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W']]\n",
    "\n",
    "    global epsilon\n",
    "    epsilon = 0.1\n",
    "    dot_count = 0\n",
    "    for list in environment:\n",
    "        dot_count += list.count('D')\n",
    "    stepcount = 0\n",
    "    while (dot_count > 0 and stepcount < max_iteration):\n",
    "        stepcount += 1\n",
    "        dot_count = 0\n",
    "        for list in environment:\n",
    "            dot_count += list.count('D')\n",
    "        #print(dot_count, epsilon)\n",
    "        if episode == 9999:\n",
    "            epsilon = 1.1\n",
    "            print(\"IN MAIN:\")\n",
    "            print(*environment, sep=\"\\n\")\n",
    "            print(*decode(encode(environment)), sep=\"\\n\")\n",
    "        current_state = encode(environment)\n",
    "        # Choose action\n",
    "        action = get_next_action(current_state)\n",
    "        # Get Reward\n",
    "        reward = get_possible_reward(current_state, action)\n",
    "        # Update Environment\n",
    "        environment = move_next_state(environment, action)\n",
    "        # Update Q\n",
    "        update_Q(current_state, action, reward, encode(environment))\n",
    "        epsilon += 0.001\n",
    "        if epsilon > 0.9:\n",
    "            epsilon = 0.9\n",
    "print(stepcount)\n",
    "test_game(environment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
